# NOTE: NUM_STEPS (max_steps_per_env) defined by env.yaml
NUM_ENVS: 4

# data gathering
EXPERT_BUFFER_SIZE: 10000 # NOTE: must be divisible by NUM_ENVS
INIT_EXPERT_TRAJ: 1000
DAGGER_ITERATIONS: 10
DAGGER_TRAJECTORIES_PER_ITER: 1000
DAGGER_BETA: 1.0 # prob of picking expert actions
# DAGGER_BETA_DECAY: 0.99 # TODO: revert linear decay?
DAGGER_BETA_LINEAR_DECAY: True

# update
DAGGER_UPDATES_PER_ITER: 100
UPDATE_BATCH_SIZE: 64
MAX_GRAD_NORM: 1
LR: 1e-4
LR_LINEAR_DECAY: False
EPS_ADAM: 0.001
WEIGHT_DECAY_ADAM: 0 # 0.001

# eval
NUM_TEST_EPISODES: 32

# agent network params
PARAMETERS_SHARING: True
AGENT_HIDDEN_DIM: 1024 # width of the RNN hidden dim + surrounding MLP layers
AGENT_RECURRENT: True
AGENT_INIT_SCALE: 2.
AGENT_HYPERAWARE: True
AGENT_HYPERNET_KWARGS:
  HIDDEN_DIM: 512 # width of hypernet
  INIT_SCALE: 0.2 # NOTE: MUST TUNE THIS
  USE_LAYER_NORM: True # whether LN is included before ReLU
  NUM_LAYERS: 4 # layers in hypernet, not target net
